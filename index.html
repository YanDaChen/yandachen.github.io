<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yanda Chen</title>

    <meta name="author" content="Yanda Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Yanda Chen</name>
                                    </p>
                                    <p>I am a third-year PhD student in Computer Science at Columbia University working
                                        on natural language processing and machine learning. I am very fortunate to be
                                        co-advised by <a href="http://www.cs.columbia.edu/~kathy/">Prof. Kathy
                                            McKeown</a>, <a href="https://hhexiy.github.io/">Prof. He He</a>, and
                                        <a href="http://www.cs.columbia.edu/~zhouyu/">Prof. Zhou Yu</a>. Previously, I
                                        received my bachelor's degree in Computer Science at Columbia University in
                                        April

                                        21.
                                    </p>
                                    <p style="text-align:center">
                                        <a href="mailto:yanda.chen@cs.columbia.edu">Email</a> &nbsp/&nbsp
                                        <a href="data/Yanda Chen CV.pdf">CV</a> &nbsp/&nbsp
                                        <a href="https://www.semanticscholar.org/author/Yanda-Chen/2109268730">Semantic
                                            Scholar</a> &nbsp/&nbsp
                                        <a href="https://twitter.com/yanda_chen_">Twitter</a> &nbsp/&nbsp
                                        <a href="https://github.com/yandachen">Github</a>
                                    </p>
                                </td>
                                <td style="padding:2.5%;width:40%;max-width:40%">
                                    <a href="images/photo.jpeg"><img style="width:80%;max-width:80%" alt="profile photo"
                                            src="images/photo.jpeg" class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:10px 20px;width:100%;vertical-align:middle">
                                    <heading>Research</heading>
                                    <p> My current research interest lies in two directions: i) Explainability: building
                                        explainable deep learning systems and understanding how LLMs behave, and ii)
                                        Reliability: improving the calibration and reducing the sensitivity of LLMs.
                                        Below are my publications.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2402.12530">
                                        <papertitle>Parallel Structures in Pre-training Data Yield In-Context Learning</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Chen Zhao, Zhou Yu, Kathleen McKeown, He He
                                    <br>
                                    <em>ACL</em>, 2024
                                    <br>
                                    <a href="https://arxiv.org/pdf/2402.12530.pdf">paper</a> &nbsp/&nbsp
                                    <a href="https://github.com/yandachen/ParallelStructuresICL">code</a>
                                    <p></p>
                                    <p>We find that ICL ability of language models emerges from parallel structures in the 
                                        pre-training data—--pairs of phrases following similar templates in the same context 
                                        window. Specifically, we show that removing parallel structures in the pre-training 
                                        data reduces LMs' ICL accuracy by 51% (vs 2% from random ablation). This drop persists 
                                        even when excluding common patterns such as n-gram repetitions and long-range dependency.</p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2401.13986">
                                        <papertitle>Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Chandan Singh, Xiaodong Liu, Simiao Zuo, Bin Yu, He He, Jianfeng Gao
                                    <br>
                                    <em>arXiv preprint</em>, 2024
                                    <br>
                                    <a href="https://arxiv.org/pdf/2401.13986.pdf">paper</a> &nbsp/&nbsp
                                    <a href="https://github.com/yandachen/explanation-consistency-finetuning">code</a>
                                    <p></p>
                                    <p>We propose <em>explanation-consistency finetuning</em> (EC-finetuning), which adapts 
                                        LLMs to generate more consistent natural-language explanations on related examples by 
                                        finetuning them on synthetic data that is carefully constructed to contain consistent 
                                        explanations. EC-finetuning improves explanation consistency by 10.0% on four finetuning 
                                        datasets, and by 4.5% on seven out-of-distribution datasets.</p>
                                </td>
                            </tr>
                            
                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2307.08678">
                                        <papertitle>Do Models Explain Themselves? Counterfactual Simulatability of
                                            Natural Language Explanations</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Ruiqi Zhong, Narutatsu Ri, Chen Zhao, He He, Jacob
                                    Steinhardt, Zhou Yu, Kathleen McKeown
                                    <br>
                                    <em>ICML</em>, 2024
                                    <br>
                                    <a href="https://arxiv.org/pdf/2307.08678.pdf">paper</a> &nbsp/&nbsp
                                    <a href="https://github.com/yandachen/CounterfactualSimulatability">code</a>
                                    <p></p>
                                    <p>We propose to evaluate the <em>counterfactual simulatability</em> of natural
                                        language explanations: whether an explanation can enable humans to precisely
                                        infer the model's outputs on diverse counterfactuals of the explained input. We
                                        implemented two metrics—precision and generality, and found that <em>i)</em>
                                        LLM's explanations have low precision, and <em>ii)</em> precision does not
                                        correlate with plausibility.</p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://aclanthology.org/2023.findings-emnlp.12">
                                        <papertitle>On the Relation between Sensitivity and Accuracy in In-context
                                            Learning</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Chen Zhao, Zhou Yu, Kathleen McKeown, He He
                                    <br>
                                    <em>EMNLP Findings</em>, 2023
                                    <br>
                                    <a href="https://aclanthology.org/2023.findings-emnlp.12.pdf">paper</a> &nbsp/&nbsp
                                    <a href="https://github.com/yandachen/ICLSensitivity">code</a> &nbsp/&nbsp
                                    <a href="data/ICLSensitivity Poster.pdf">poster</a>
                                    <p></p>
                                    <p>We find that label bias obscures true ICL sensitivity and that ICL sensitivity is
                                        strongly and negatively correlated with accuracy. Motivated by our study, we
                                        propose <em>SenSel</em>, a few-shot selective prediction method based on ICL
                                        sensitivity.</p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2212.10670">
                                        <papertitle>In-context Learning Distillation: Transferring Few-shot Learning
                                            Ability of Pre-trained Language Models</papertitle>
                                    </a>
                                    <br>
                                    Yukun Huang, <strong>Yanda Chen</strong>, Zhou Yu, Kathleen McKeown
                                    <br>
                                    <em>arXiv preprint</em>, 2022
                                    <br>
                                    <a href="https://arxiv.org/pdf/2212.10670.pdf">paper</a>
                                    <p></p>
                                    <p>We proposed in-context learning distillation, which transfers in-context learning
                                        (ICL) ability from large language models to small language models by augmenting
                                        in-context tuning with teacher-student distillation. Experiments on LAMA and
                                        CrossFit show that in-context learning distillation improves the ICL ability of
                                        small language models.</p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://aclanthology.org/2022.acl-long.53/">
                                        <papertitle>Meta-learning via Language Model In-context Tuning</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Ruiqi Zhong, Sheng Zha, George Karypis, He He
                                    <br>
                                    <em>ACL</em>, 2022
                                    <br>
                                    <a href="https://aclanthology.org/2022.acl-long.53.pdf">paper</a> &nbsp/&nbsp
                                    <a href="https://github.com/yandachen/In-context-Tuning">code</a> &nbsp/&nbsp
                                    <a href="data/ICT-ACL-Slides.pdf">slides</a>
                                    <p></p>
                                    <p>We propose a novel few-shot meta-learning method called <em>in-context
                                            tuning</em>, where training examples are used as prefix in-context
                                        demonstrations for task adaptation. We show that in-context tuning out-performs
                                        MAML in terms of accuracy and eliminates several well-known oversensitivity
                                        artifacts of few-shot language model prompting. </p>
                                </td>
                            </tr>


                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://aclanthology.org/2021.acl-long.300/">
                                        <papertitle>Cross-language Sentence Selection via Data Augmentation and
                                            Rationale Training</papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Chris Kedzie, Suraj Nair, Petra Galuscakova, Rui Zhang,
                                    Douglas Oard, Kathleen McKeown
                                    <br>
                                    <em>ACL</em>, 2021
                                    <br>
                                    <a href="https://aclanthology.org/2021.acl-long.300.pdf">paper</a> &nbsp/&nbsp
                                    <a href="https://github.com/yandachen/Low-resource-CLSS">code</a> &nbsp/&nbsp
                                    <a
                                        href="https://underline.io/lecture/25655-cross-language-sentence-selection-via-data-augmentation-and-rationale-training">talk</a>
                                    &nbsp/&nbsp
                                    <a href="data/clss_slides.key">slides</a>
                                    <p></p>
                                    <p>We propose a data augmentation strategy and a rationale training strategy for
                                        cross-lingual sentence selection in low-resource settings where no labeled
                                        relevance judgment is available for training. Our methods achieve
                                        state-of-the-art results on three language pairs.</p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://arxiv.org/abs/2010.12776">
                                        <papertitle>Improved Synthetic Training for Reading Comprehension
                                        </papertitle>
                                    </a>
                                    <br>
                                    <strong>Yanda Chen</strong>, Md Arafat Sultan, Vittorio Castelli
                                    <br>
                                    <em>arXiv preprint</em>, 2020
                                    <br>
                                    <a href="https://arxiv.org/abs/2010.12776">paper</a>
                                    <p></p>
                                    <p>We propose two novel synthetic training strategies: targeted synthetic
                                        pre-training (a method to select useful synthetic examples to target weakness of
                                        existing models) and synthetic knowledge distillation. The two techniques, when
                                        combined, yield QA models that are simultaneously smaller, faster, and more
                                        accurate. </p>
                                </td>
                            </tr>


                            <tr>
                                <td style="padding: 10px 20px;width:75%;vertical-align:middle">
                                    <a href="https://aclanthology.org/D19-1483/">
                                        <papertitle>Detecting and Reducing Bias in a High Stakes Domain</papertitle>
                                    </a>
                                    <br>
                                    Ruiqi Zhong, <strong>Yanda Chen</strong>, Desmond Patton, Charlotte Selous, Kathy
                                    McKeown
                                    <br>
                                    <em>EMNLP</em>, 2019
                                    <br>
                                    <a href="https://aclanthology.org/D19-1483/">paper</a>
                                    /
                                    <a href="https://github.com/yandachen/GI_2019">code</a>
                                    /
                                    <a href="data/gi_poster.pdf">poster</a>
                                    <p></p>
                                    <p>We propose a framework to systematically detect and reduce language bias of deep
                                        learning models under the high-stakes context of gang intervention.</p>
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px 20px 5px 20px;width:100%;vertical-align:middle">
                                    <heading>Internships</heading>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px 20px 10px 20px;width:75%;vertical-align:middle">
                                    Google Research (Student Researcher), <em>Spring & Summer 2024</em>, Manager: Sjoerd van Steenkiste, Tal Linzen
                                    <br><br>
                                    Microsoft Research, <em>Summer 2023</em>, Mentor: Chandan Singh
                                    <br><br>
                                    AWS AI, <em>Summer 2021</em>, Mentor: He He
                                    <br><br>
                                    IBM Research, <em>Summer 2020</em>, Mentor: Arafat Sultan, Vittorio Castelli
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px 20px 5px 20px;width:100%;vertical-align:middle">
                                    <heading>Honors</heading>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px 20px 10px 20px;width:75%;vertical-align:middle">
                                    Avanessians Doctoral Fellowships for Engineering Thought Leaders and Innovators in Data Science. 2023.
                                    <br><br>
                                    Mudd Doctoral Fellowship, Columbia SEAS. 2021.
                                    <br><br>
                                    Honorable Mention, CRA Undergraduate Research Awards. 2021.
                                    <br><br>
                                    Theodore R. Bashkow Research Award, Columbia Computer Science Dept. 2021.
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px 20px 5px 20px;width:100%;vertical-align:middle">
                                    <heading>Teaching Assistant</heading>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px 20px 10px 20px;width:75%;vertical-align:middle">
                                    Natural Language Processing, Spring 2022 & Spring 2021
                                    <br><br>
                                    Analysis of Algorithms, Spring 2021 & Spring 2020
                                    <br><br>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:small;">
                                        Website design from <a href="https://github.com/jonbarron/jonbarron_website">Jon
                                            Barron</a>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </table>
</body>

</html>
